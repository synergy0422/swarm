---
phase: 24-swarm_tasks_bridge_sh
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - /home/user/projects/AAA/swarm/scripts/swarm_tasks_bridge.sh
autonomous: true
must_haves:
  truths:
    - "claim subcommand acquires lock and logs START status"
    - "done subcommand releases lock and logs DONE status"
    - "fail subcommand logs ERROR status with reason"
    - "lock conflict results in exit code 2 with holder information"
    - "All errors are printed to stderr with actionable messages"
  artifacts:
    - path: "/home/user/projects/AAA/swarm/scripts/swarm_tasks_bridge.sh"
      provides: "CLI script with claim/done/fail commands"
      commands:
        - claim
        - done
        - fail
      exit_codes:
        claim: "0=success, 2=lock occupied, 1=other failure"
        done: "0=success, 1=failure"
        fail: "0=success, 1=failure"
  key_links:
    - from: "swarm_tasks_bridge.sh claim"
      to: "swarm_lock.sh acquire"
      via: "lock acquisition"
    - from: "swarm_tasks_bridge.sh claim"
      to: "swarm_status_log.sh append START"
      via: "status logging"
    - from: "swarm_tasks_bridge.sh done/fail"
      to: "swarm_lock.sh release"
      via: "lock release"
    - from: "swarm_tasks_bridge.sh done"
      to: "swarm_status_log.sh append DONE"
      via: "status logging"
    - from: "swarm_tasks_bridge.sh fail"
      to: "swarm_status_log.sh append ERROR"
      via: "status logging with reason"
---

<objective>
Create `scripts/swarm_tasks_bridge.sh` CLI script that bridges CLAUDE_CODE_TASK_LIST_ID tasks with swarm lock/state system, implementing automatic claim→lock→work→done/fail闭环.

**Purpose:** Enable Claude Tasks workers to claim tasks, automatically acquire locks and log START, then complete with DONE or ERROR status while handling lock release automatically.

**Output:** Executable bash script at `/home/user/projects/AAA/swarm/scripts/swarm_tasks_bridge.sh` with:
- `claim <task_id> <worker> [lock_key]` — acquire lock + START log
- `done <task_id> <worker> [lock_key]` — release lock + DONE log
- `fail <task_id> <worker> <reason> [lock_key]` — release lock + ERROR log
</objective>

<execution_context>
@/home/user/.claude/get-shit-done/workflows/execute-plan.md
</execution_context>

<context>
@/home/user/projects/AAA/swarm/.planning/ROADMAP.md
@/home/user/projects/AAA/swarm/.planning/STATE.md

Reference existing scripts for patterns:
- `/home/user/projects/AAA/swarm/scripts/swarm_task_wrap.sh` — command structure, `set -euo pipefail`, usage function
- `/home/user/projects/AAA/swarm/scripts/swarm_lock.sh` — acquire/release exit codes, error messages
- `/home/user/projects/AAA/swarm/scripts/swarm_status_log.sh` — append command with type/worker/task_id/reason

**Implementation decisions from CONTEXT:**
- claim exit codes: 0=success, 2=lock occupied, 1=other failure
- done/fail exit codes: 0=success, 1=failure
- Worker must match `worker-0`, `worker-1`, or `worker-2`
- lock_key defaults to task_id if not provided
- lock_key must not contain spaces
- fail reason is required (no default)
- All errors printed to stderr, never swallowed
</context>

<tasks>

<task type="auto">
  <name>Create swarm_tasks_bridge.sh script framework with dependency checks</name>
  <files>/home/user/projects/AAA/swarm/scripts/swarm_tasks_bridge.sh</files>
  <action>
    Create the script with:
    1. `set -euo pipefail` header
    2. SCRIPT_DIR detection and source `_common.sh`
    3. **Dependency validation** (at script start):
       - Check `swarm_lock.sh` exists in `SCRIPT_DIR/`
       - Check `swarm_status_log.sh` exists in `SCRIPT_DIR/`
       - If any missing: print "Error: Missing dependency: scripts/NAME" to stderr and exit 1
    4. Usage function with all subcommands documented:
       - `claim <task_id> <worker> [lock_key]` — acquire lock + log START
       - `done <task_id> <worker> [lock_key]` — release lock + log DONE
       - `fail <task_id> <worker> <reason> [lock_key]` — release lock + log ERROR
    5. Main entry point with command parsing
    6. Helper functions: `validate_worker`, `validate_lock_key`

    Reference `swarm_task_wrap.sh` structure for consistency.
  </action>
  <verify>
    Test dependency check:
    ```bash
    # Temporarily rename dependency to test error
    mv scripts/swarm_lock.sh scripts/swarm_lock.sh.bak 2>/dev/null || true
    ./scripts/swarm_tasks_bridge.sh --help 2>&1 | grep -q "Missing dependency" && echo "Dependency check works"
    mv scripts/swarm_lock.sh.bak scripts/swarm_lock.sh 2>/dev/null || true
    ```
    `./scripts/swarm_tasks_bridge.sh --help` displays usage with all commands
    Script is executable: `test -x scripts/swarm_tasks_bridge.sh`
  </verify>
  <done>
    Script framework exists with dependency validation and help output
  </done>
</task>

<task type="auto">
  <name>Implement claim subcommand</name>
  <files>/home/user/projects/AAA/swarm/scripts/swarm_tasks_bridge.sh</files>
  <action>
    Implement `cmd_claim()` function that:
    1. Validates parameters (task_id, worker required)
    2. Validates worker matches `worker-0|worker-1|worker-2`
    3. Defaults lock_key to task_id if not provided
    4. Validates lock_key has no spaces
    5. Calls `swarm_lock.sh acquire <lock_key> <worker>`
    6. On success: calls `swarm_status_log.sh append START <worker> <task_id>`
    7. On lock occupied: exits with code 2, prints which worker holds the lock
    8. On other failure: exits with code 1, prints error to stderr

    Success output: `Claimed task '<task_id>' (lock: '<lock_key>')`
    Lock occupied: `Error: Lock held by '<worker>' for '<lock_key>' (exit 2)`
  </action>
  <verify>
    Test claim success (with isolated directory):
    ```bash
    TEST_DIR=$(mktemp -d) && export SWARM_STATE_DIR="$TEST_DIR" && mkdir -p "$TEST_DIR/locks"

    # Test claim (should succeed, exit 0)
    ./scripts/swarm_tasks_bridge.sh claim task-test-01 worker-0
    echo "Exit: $?"

    # Verify lock created
    cat "$TEST_DIR/locks/task-test-01.lock"

    # Verify status logged
    ./scripts/swarm_status_log.sh query task-test-01 | grep START

    rm -rf "$TEST_DIR"
    ```

    Test lock conflict:
    ```bash
    TEST_DIR=$(mktemp -d) && export SWARM_STATE_DIR="$TEST_DIR" && mkdir -p "$TEST_DIR/locks"

    # Hold lock from another worker
    ./scripts/swarm_lock.sh acquire task-test-conflict worker-1

    # Try to claim from worker-0 (should fail, exit 2)
    ./scripts/swarm_tasks_bridge.sh claim task-test-conflict worker-0
    echo "Exit: $?"

    # Cleanup
    rm -rf "$TEST_DIR"
    ```
  </verify>
  <done>
    claim subcommand acquires lock, logs START, exits 0 on success, exits 2 on conflict
  </done>
</task>

<task type="auto">
  <name>Implement done subcommand</name>
  <files>/home/user/projects/AAA/swarm/scripts/swarm_tasks_bridge.sh</files>
  <action>
    Implement `cmd_done()` function that:
    1. Validates parameters (task_id, worker required)
    2. Validates worker matches `worker-0|worker-1|worker-2`
    3. Defaults lock_key to task_id if not provided
    4. Validates lock_key has no spaces
    5. Calls `swarm_lock.sh release <lock_key> <worker>`
    6. On success: calls `swarm_status_log.sh append DONE <worker> <task_id>`
    7. On failure (wrong worker, no lock): exits with code 1, prints error to stderr

    Success output: `Completed task '<task_id>' (lock: '<lock_key>')`
  </action>
  <verify>
    Test done after claim (with isolated directory):
    ```bash
    TEST_DIR=$(mktemp -d) && export SWARM_STATE_DIR="$TEST_DIR" && mkdir -p "$TEST_DIR/locks"

    # Claim a task first
    ./scripts/swarm_tasks_bridge.sh claim task-test-done worker-1

    # Complete the task (should succeed, exit 0)
    ./scripts/swarm_tasks_bridge.sh done task-test-done worker-1
    echo "Exit: $?"

    # Verify lock removed
    test ! -f "$TEST_DIR/locks/task-test-done.lock" && echo "Lock released"

    # Verify status logged
    ./scripts/swarm_status_log.sh query task-test-done | grep DONE

    rm -rf "$TEST_DIR"
    ```

    Test done with custom lock_key:
    ```bash
    TEST_DIR=$(mktemp -d) && export SWARM_STATE_DIR="$TEST_DIR" && mkdir -p "$TEST_DIR/locks"
    ./scripts/swarm_tasks_bridge.sh claim task-test-custom worker-0 custom-lock
    ./scripts/swarm_tasks_bridge.sh done task-test-custom worker-0 custom-lock
    rm -rf "$TEST_DIR"
    ```
  </verify>
  <done>
    done subcommand releases lock, logs DONE, exits 0 on success, exits 1 on failure
  </done>
</task>

<task type="auto">
  <name>Implement fail subcommand</name>
  <files>/home/user/projects/AAA/swarm/scripts/swarm_tasks_bridge.sh</files>
  <action>
    Implement `cmd_fail()` function that:
    1. Validates parameters (task_id, worker, reason all required)
    2. Validates worker matches `worker-0|worker-1|worker-2`
    3. Defaults lock_key to task_id if not provided
    4. Validates lock_key has no spaces
    5. Validates reason is non-empty (no trimming, but must exist)
    6. Calls `swarm_lock.sh release <lock_key> <worker>`
    7. On success: calls `swarm_status_log.sh append ERROR <worker> <task_id> "<reason>"`
    8. On failure: exits with code 1, prints error to stderr

    Success output: `Failed task '<task_id>' (lock: '<lock_key>'): <reason>`
  </action>
  <verify>
    Test fail after claim (with isolated directory):
    ```bash
    TEST_DIR=$(mktemp -d) && export SWARM_STATE_DIR="$TEST_DIR" && mkdir -p "$TEST_DIR/locks"

    # Claim a task first
    ./scripts/swarm_tasks_bridge.sh claim task-test-fail worker-2

    # Fail the task (should succeed, exit 0)
    ./scripts/swarm_tasks_bridge.sh fail task-test-fail worker-2 "Something went wrong"
    echo "Exit: $?"

    # Verify lock removed
    test ! -f "$TEST_DIR/locks/task-test-fail.lock" && echo "Lock released"

    # Verify status logged with reason
    ./scripts/swarm_status_log.sh query task-test-fail | grep ERROR | grep "Something went wrong"

    rm -rf "$TEST_DIR"
    ```

    Test fail without reason (should fail):
    ```bash
    ./scripts/swarm_tasks_bridge.sh fail task-test-noreason worker-0 2>&1 | grep -i "reason"
    ```
  </verify>
  <done>
    fail subcommand releases lock, logs ERROR with reason, exits 0 on success, exits 1 on failure
  </done>
</task>

</tasks>

<verification>
## Integration Test: Full Workflow

Run this complete workflow test with isolated temporary directory:

```bash
# Create isolated test directory
TEST_DIR=$(mktemp -d)
export SWARM_STATE_DIR="$TEST_DIR"

# Create required subdirectories
mkdir -p "$TEST_DIR/locks"

# Step 1: Claim task
echo "=== Step 1: Claim ==="
./scripts/swarm_tasks_bridge.sh claim task-verify-01 worker-0
echo "Claim exit: $?"

# Verify lock exists
echo "Lock exists: $(test -f "$TEST_DIR/locks/task-verify-01.lock" && echo yes || echo no)"

# Verify START logged
echo "START logged: $(./scripts/swarm_status_log.sh query task-verify-01 | grep -c START)"

# Step 2: Complete task
echo ""
echo "=== Step 2: Done ==="
./scripts/swarm_tasks_bridge.sh done task-verify-01 worker-0
echo "Done exit: $?"

# Verify lock released
echo "Lock released: $(test ! -f "$TEST_DIR/locks/task-verify-01.lock" && echo yes || echo no)"

# Verify DONE logged
echo "DONE logged: $(./scripts/swarm_status_log.sh query task-verify-01 | grep -c DONE)"

# Step 3: Fail workflow
echo ""
echo "=== Step 3: Fail ==="
./scripts/swarm_tasks_bridge.sh claim task-verify-02 worker-1
./scripts/swarm_tasks_bridge.sh fail task-verify-02 worker-1 "Test failure reason"
echo "Fail exit: $?"

# Verify ERROR logged with reason
echo "ERROR logged: $(./scripts/swarm_status_log.sh query task-verify-02 | grep -c ERROR)"
echo "Reason included: $(./scripts/swarm_status_log.sh query task-verify-02 | grep -c 'Test failure reason')"

# Step 4: Lock conflict test
echo ""
echo "=== Step 4: Lock Conflict ==="
./scripts/swarm_tasks_bridge.sh claim task-verify-03 worker-0
./scripts/swarm_tasks_bridge.sh claim task-verify-03 worker-1 2>&1
echo "Conflict exit: $? (should be 2)"

# Cleanup
rm -rf "$TEST_DIR"
```

Expected results:
- Claim exit: 0
- Done exit: 0
- Fail exit: 0
- Conflict exit: 2
- All status logs present
- All locks properly released
</verification>

<success_criteria>
1. **Script Functions Correctly**
   - `claim` acquires lock and logs START
   - `done` releases lock and logs DONE
   - `fail` releases lock and logs ERROR with reason

2. **Exit Codes Correct**
   - claim success: 0
   - claim lock conflict: 2
   - claim other error: 1
   - done/fail success: 0
   - done/fail error: 1

3. **Error Handling**
   - Lock conflicts show which worker holds the lock
   - All errors print to stderr
   - No errors are swallowed silently

4. **No Manual Swarm_lock.sh Calls Needed**
   - claim + done workflow completes without manual `swarm_lock.sh` calls
   - claim + fail workflow completes without manual `swarm_lock.sh` calls
</success_criteria>

<output>
After completion, create `.planning/phases/24-swarm_tasks_bridge_sh/24-01-SUMMARY.md`
</output>
